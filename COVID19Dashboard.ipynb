{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID19Dashboard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMsGuy3wwx+C2akwCnSLUca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yy20190404/db_covid/blob/master/COVID19Dashboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fKPrxkIWtsQ",
        "colab_type": "text"
      },
      "source": [
        "# COVID19-Dashboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bKkl797W-2A",
        "colab_type": "text"
      },
      "source": [
        "## Collect COVID19 data from web"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74_fubMipVjL",
        "colab_type": "text"
      },
      "source": [
        "### install python libraries, make directories\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSaqamHNqG3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!python -m pip install requests-html\n",
        "!python -m pip install seaborn\n",
        "!pip install japanize-matplotlib\n",
        "!python -m pip install flask\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "!mkdir templates\n",
        "!mkdir static\n",
        "!mkdir static/img\n",
        "!mkdir static/csv\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "!cp drive/'My Drive'/'Colab Notebooks'/japan-map-master/japan-map.jquery.json templates/\n",
        "!cp drive/'My Drive'/'Colab Notebooks'/japan-map-master/jquery.japan-map.js templates/\n",
        "!cp drive/'My Drive'/'Colab Notebooks'/japan-map-master/jquery.japan-map.min.js templates/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDlACgyHXIQ6",
        "colab_type": "text"
      },
      "source": [
        "### Reshape data to use dashboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KNjh_FTv3X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dldata = \"\"\"\n",
        "\n",
        "#!/usr/bin/env python\n",
        "#-*- coding:utf-8 -*-\n",
        "\n",
        "import datetime\n",
        "import gc\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import requests\n",
        "from requests_html import HTMLSession\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_converted_multi_columns(df, just_second=False, to_snake_case=True):\n",
        "  if just_second:\n",
        "    return [col[1] for col in df.columns.values]\n",
        "  else:\n",
        "    if to_snake_case:\n",
        "        return [col[0] + '_' + col[1] for col in df.columns.values]\n",
        "    else:\n",
        "        return [col[0] + col[1].capitalize() for col in df.columns.values]\n",
        "\n",
        "def down_load():\n",
        "  HEADERS_DIC = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36\"}\n",
        "  URLWW1 = \"https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv&filename=time_series_covid19_confirmed_global.csv\"\n",
        "  URLWW2 = \"https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv&filename=time_series_covid19_deaths_global.csv\"\n",
        "  URLWW3 = \"https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_recovered_global.csv&filename=time_series_covid19_recovered_global.csv\"\n",
        "  URLJP  = \"https://dl.dropboxusercontent.com/s/6mztoeb6xf78g5w/COVID-19.csv\"\n",
        "  SAVE_NAMES = [\"covid19_ww_confirmed_global.csv\", \"covid19_ww_deaths_global.csv\",\"covid19_ww_recovered_global.csv\", \"covid19_jp.csv\"]\n",
        "  DIRCSV = \"./static/csv/\"\n",
        "  urls = [URLWW1, URLWW2, URLWW3, URLJP]\n",
        "  del_cols = [\"Province/State\", \"Lat\", \"Long\"]\n",
        "  \n",
        "  ##############################################################################\n",
        "  ## Reshape of worldwide COVID19 daily numbers csv\n",
        "  ##############################################################################\n",
        "  today = datetime.date.today()\n",
        "  save_names = SAVE_NAMES.copy()\n",
        "  del save_names[-1]\n",
        "  i = 0\n",
        "  for f_name in save_names:\n",
        "    # Download a target file if it is not exist\n",
        "    if os.path.isfile(DIRCSV + f_name) == False:\n",
        "      r = requests.get(urls[i], headers=HEADERS_DIC)\n",
        "      with open(DIRCSV + f_name, mode='w', encoding='utf_8') as f:\n",
        "        f.write(r.text)\n",
        "\n",
        "      ## Reshape csv file\n",
        "      df = pd.read_csv(DIRCSV + f_name)\n",
        "      ### Drop unnessesary columns\n",
        "      df = df.drop(del_cols, axis=1) \n",
        "      ### Reshape date style          \n",
        "      cols = df.columns\n",
        "      dates = []\n",
        "      for col in cols:\n",
        "        if col == 'Country/Region':\n",
        "          dates.append(col)\n",
        "        else:\n",
        "          day = datetime.datetime.strptime(col, '%m/%d/%y')  \n",
        "          dates.append(day.strftime('%Y-%m-%d'))\n",
        "      df.columns = dates\n",
        "      ### Group and sum each country\n",
        "      df = df.groupby(\"Country/Region\").sum()\n",
        "      ### Save as csv file\n",
        "      df.to_csv(DIRCSV + f_name, encoding='utf_8_sig')\n",
        "      ### Delete dataframe instance\n",
        "      del df\n",
        "    else:\n",
        "      ### Get file datetime\n",
        "      dt = os.path.getmtime(DIRCSV + f_name)\n",
        "      dt = datetime.datetime.fromtimestamp(dt)\n",
        "      dt = dt.strftime('%Y-%m-%d')\n",
        "      ## Download and reshape csv file when the exist file not made on today\n",
        "      if str(dt) != str(today):\n",
        "        r = requests.get(urls[i], headers=HEADERS_DIC)\n",
        "        with open(DIRCSV + f_name, mode='w', encoding='utf_8') as f:\n",
        "          f.write(r.text)\n",
        "        df = pd.read_csv(DIRCSV + f_name)\n",
        "        df = df.drop(del_cols, axis=1) \n",
        "        cols = df.columns\n",
        "        dates = []\n",
        "        for col in cols:\n",
        "          if col == 'Country/Region':\n",
        "            dates.append(col)\n",
        "          else:\n",
        "            day = datetime.datetime.strptime(col, '%m/%d/%y')  \n",
        "            dates.append(day.strftime('%Y-%m-%d'))\n",
        "        df.columns = dates\n",
        "        ### Group and sum each countory\n",
        "        df = df.groupby(\"Country/Region\").sum()\n",
        "        df = df.set_index('Country/Region')\n",
        "        ### Save as csv file\n",
        "        df.to_csv(DIRCSV + f_name, encoding='utf_8_sig')\n",
        "        ### Delete dataframe instance\n",
        "        del df\n",
        "    i += 1\n",
        "\n",
        "  ##############################################################################\n",
        "  ## Reshape of Japanese COVID19 daily numbers csv\n",
        "  ##############################################################################\n",
        "  f_name = SAVE_NAMES[3]\n",
        "  today = datetime.date.today()\n",
        "  # Download a target file if it is not exist\n",
        "  if os.path.isfile(DIRCSV + f_name) == False:\n",
        "    r = requests.get(urls[3], headers=HEADERS_DIC)\n",
        "    with open(DIRCSV + f_name, mode='w', encoding='utf_8') as f:\n",
        "      f.write(r.text)\n",
        "  else:\n",
        "    dt = os.path.getmtime(DIRCSV + f_name)\n",
        "    dt = datetime.datetime.fromtimestamp(dt)\n",
        "    dt = dt.strftime('%Y-%m-%d')\n",
        "    if today != dt:\n",
        "      r = requests.get(urls[3], headers=HEADERS_DIC)\n",
        "      with open(DIRCSV + f_name, mode='w', encoding='utf_8') as f:\n",
        "        f.write(r.text)\n",
        "  ## Reshape csv file\n",
        "  df = pd.read_csv(DIRCSV + f_name)\n",
        "  \n",
        "  ################################################################################\n",
        "  ## Download of Japanese COVID19 data\n",
        "  ## Reshape the data\n",
        "  ################################################################################\n",
        "  cols = df.columns\n",
        "  df = df.loc[:, [\"通し\", \"受診都道府県\", \"確定日\", \"更新日時\", \"年代\", \"性別\", \"ステータス\", \"人数\"]]\n",
        "  df.columns = [\"No.\", \"Prefecture\", \"Date\", \"Saved_Date\", \"Genelation\", \"Sex\", \"Status\", \"Number\"]\n",
        "  df['Status'] = df['Status'].replace(np.nan, \"confirmed\")\n",
        "  df['Status'] = df['Status'].replace('退院', \"recovered\")\n",
        "  df['Status'] = df['Status'].replace('死(.*)', \"death\", regex=True)\n",
        "  df['Prefecture'] = df['Prefecture'].replace('中部国際空港', '愛知県')\n",
        "  df['Prefecture'] = df['Prefecture'].replace('成田空港', '千葉県')\n",
        "  df['Prefecture'] = df['Prefecture'].replace('羽田空港', '東京都')\n",
        "  df['Prefecture'] = df['Prefecture'].replace('関西国際空港', '大阪府')\n",
        "  sr = df['Saved_Date']\n",
        "  modified_date = str(sr[0])\n",
        "  modified_date = datetime.datetime.strptime(modified_date, '%m/%d/%Y %H:%M')\n",
        "  modified_date = modified_date.strftime('%Y-%m-%d %H:%M')\n",
        "  df.at[0, 'Saved_Date'] = modified_date\n",
        "  df = df.dropna(subset=[\"Date\"])\n",
        "  dates = []\n",
        "  for date in df['Date']:\n",
        "    day = datetime.datetime.strptime(str(date), '%m/%d/%Y')\n",
        "    dates.append(day.strftime('%Y-%m-%d'))\n",
        "  df['Date'] = dates\n",
        "  df.to_csv(DIRCSV + \"covid19_jp_all.csv\", encoding='utf_8_sig')\n",
        "\n",
        "  ## 日本の都道府県別・日付別発症者数リスト\n",
        "  dfc = df.drop([\"No.\", \"Saved_Date\", \"Genelation\", \"Sex\", \"Status\"], axis=1)\n",
        "  dfc = dfc.groupby([\"Prefecture\", \"Date\"]).sum().unstack()\n",
        "  dfc = dfc.replace(np.nan, 0.0)\n",
        "  dfc.columns = get_converted_multi_columns(dfc, just_second=True)\n",
        "  dfc.to_csv(DIRCSV + \"covid19_jp_prf_cfm.csv\", encoding='utf_8_sig')\n",
        "\n",
        "  ## 日本の都道府県別・日付別死者数リスト\n",
        "  dfc = df.drop([\"No.\", \"Saved_Date\", \"Genelation\", \"Sex\", \"Number\"], axis=1)\n",
        "  dfc = dfc[dfc[\"Status\"] != \"confirmed\"]\n",
        "  dfc = dfc[dfc[\"Status\"] != \"recovered\"]\n",
        "  dfc[\"Status\"] = 1\n",
        "  dfc = dfc.groupby([\"Prefecture\", \"Date\"]).sum().unstack()\n",
        "  dfc = dfc.replace(np.nan, 0.0)\n",
        "  dfc.columns = get_converted_multi_columns(dfc, just_second=True)\n",
        "  dfc.to_csv(DIRCSV + \"covid19_jp_prf_dth.csv\", encoding='utf_8_sig')\n",
        "  \n",
        "  ## 日本の都道府県別・日付別退院者数リスト\n",
        "  dfc = df.drop([\"No.\", \"Saved_Date\", \"Genelation\", \"Sex\", \"Number\"], axis=1)\n",
        "  dfc = dfc[dfc[\"Status\"] != \"confirmed\"]\n",
        "  dfc = dfc[dfc[\"Status\"] != \"death\"]\n",
        "  dfc[\"Status\"] = 1\n",
        "  dfc = dfc.groupby([\"Prefecture\", \"Date\"]).sum().unstack()\n",
        "  dfc = dfc.replace(np.nan, 0.0)\n",
        "  dfc.columns = get_converted_multi_columns(dfc, just_second=True)\n",
        "  dfc.to_csv(DIRCSV + \"covid19_jp_prf_rcv.csv\", encoding='utf_8_sig')\n",
        "\n",
        "  ## 日本の都道府県別・ 男性数リスト\n",
        "  dfc = df.drop([\"No.\", \"Saved_Date\", \"Genelation\", \"Status\", \"Number\"], axis=1)\n",
        "  dfc = dfc[dfc[\"Sex\"] != \"女性\"]\n",
        "  dfc[\"Sex\"] = 1\n",
        "  dfc = dfc.groupby([\"Prefecture\", \"Date\"]).sum().unstack()\n",
        "  dfc = dfc.replace(np.nan, 0.0)\n",
        "  dfc.columns = get_converted_multi_columns(dfc, just_second=True)\n",
        "  dfc.to_csv(DIRCSV + \"covid19_jp_prf_male.csv\", encoding='utf_8_sig')\n",
        "\n",
        "  ## 日本の都道府県別・ 女性数リスト\n",
        "  dfc = df.drop([\"No.\", \"Saved_Date\", \"Genelation\", \"Status\", \"Number\"], axis=1)\n",
        "  dfc = dfc[dfc[\"Sex\"] != \"男性\"]\n",
        "  dfc[\"Sex\"] = 1\n",
        "  dfc = dfc.groupby([\"Prefecture\", \"Date\"]).sum().unstack()\n",
        "  dfc = dfc.replace(np.nan, 0.0)\n",
        "  dfc.columns = get_converted_multi_columns(dfc, just_second=True)\n",
        "  dfc.to_csv(DIRCSV + \"covid19_jp_prf_female.csv\", encoding='utf_8_sig')\n",
        "\n",
        "  ## 日本の都道府県別・ 年代別リスト\n",
        "  dfc = df.drop([\"No.\", \"Date\", \"Saved_Date\", \"Sex\", \"Status\"], axis=1)\n",
        "  dfc = dfc.replace(np.nan, 99.0)\n",
        "  dfc = dfc.replace(\"0-10\", 1.0)\n",
        "  dfc = dfc.replace(\"10\", 10.0)\n",
        "  dfc = dfc.replace(\"20\", 20.0)\n",
        "  dfc = dfc.replace(\"30\", 30.0)\n",
        "  dfc = dfc.replace(\"40\", 40.0)\n",
        "  dfc = dfc.replace(\"50\", 50.0)\n",
        "  dfc = dfc.replace(\"60\", 60.0)\n",
        "  dfc = dfc.replace(\"70\", 70.0)\n",
        "  dfc = dfc.replace(\"80\", 80.0)\n",
        "  dfc = dfc.replace(\"90\", 90.0)\n",
        "  dfc = dfc.replace(10, 10.0)\n",
        "  dfc = dfc.replace(20, 20.0)\n",
        "  dfc = dfc.replace(30, 30.0)\n",
        "  dfc = dfc.replace(40, 40.0)\n",
        "  dfc = dfc.replace(50, 50.0)\n",
        "  dfc = dfc.replace(60, 60.0)\n",
        "  dfc = dfc.replace(70, 70.0)\n",
        "  dfc = dfc.replace(80, 80.0)\n",
        "  dfc = dfc.replace(90, 90.0)\n",
        "  dfc[\"Genelation\"] = dfc[\"Genelation\"].replace(\"不明\", 99.0)\n",
        "  dfc[\"Genelation\"] = dfc[\"Genelation\"].astype(int)\n",
        "  dfc = dfc.groupby([\"Prefecture\", \"Genelation\"]).sum().unstack()\n",
        "  dfc.columns = get_converted_multi_columns(dfc, just_second=True)\n",
        "  dfc = dfc.replace(np.nan, 0.0)\n",
        "  dfc = dfc.astype(int)\n",
        "  dfc.to_csv(DIRCSV + \"covid19_jp_prf_gen.csv\", encoding='utf_8_sig')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  down_load()\n",
        "\"\"\"\n",
        "\n",
        "  \n",
        "with open('dldata.py', mode='w', encoding='utf_8') as f:\n",
        "  f.write(dldata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2SCT8AoXkat",
        "colab_type": "text"
      },
      "source": [
        "### Make files to use dashboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2PciUKScU_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install plotly\n",
        "!pip install dash\n",
        "!pip install dash-html-components\n",
        "!pip install dash-core-components\n",
        "!pip install dash-table\n",
        "!pip install dash-daq \n",
        "!pip install dash_bootstrap_components"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbm2SpV0X8Ed",
        "colab_type": "text"
      },
      "source": [
        "## Dashboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWWIhqUyB2U4",
        "colab_type": "text"
      },
      "source": [
        "### Build internal server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7lRxIVEkbw5",
        "colab_type": "text"
      },
      "source": [
        "### app.pyの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q50bHWo_jCQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dashfile = \"\"\"\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import datetime\n",
        "import dash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DIRCSV = 'static/csv/'\n",
        "CSV_FILES = ('covid19_ww_confirmed_global.csv',\n",
        "            'covid19_ww_deaths_global.csv',\n",
        "            'covid19_ww_recovered_global.csv',\n",
        "            'covid19_jp_prf_cfm.csv',\n",
        "            'covid19_jp_prf_dth.csv',\n",
        "            'covid19_jp_prf_rcv.csv',\n",
        "            'covid19_jp_prf_male.csv',\n",
        "            'covid19_jp_prf_female.csv',\n",
        "            'covid19_jp_prf_gen.csv')\n",
        "\n",
        "df0 = pd.read_csv(DIRCSV + CSV_FILES[0])\n",
        "df1 = pd.read_csv(DIRCSV + CSV_FILES[1])\n",
        "df2 = pd.read_csv(DIRCSV + CSV_FILES[2])\n",
        "df3 = pd.read_csv(DIRCSV + CSV_FILES[3])\n",
        "df4 = pd.read_csv(DIRCSV + CSV_FILES[4])\n",
        "df5 = pd.read_csv(DIRCSV + CSV_FILES[5])\n",
        "df6 = pd.read_csv(DIRCSV + CSV_FILES[6])\n",
        "df7 = pd.read_csv(DIRCSV + CSV_FILES[7])\n",
        "df8 = pd.read_csv(DIRCSV + CSV_FILES[8])\n",
        "\n",
        "df0 = df0.set_index('Country/Region')\n",
        "df0.loc['Worldwide'] = df0.sum()\n",
        "df0_x = df0.columns.tolist()\n",
        "df0_y = df0.loc['Worldwide', ].tolist()\n",
        "df0_z = df0.index.tolist()\n",
        "dict0 = []\n",
        "for x in df0_z:\n",
        "  dict0.append({'label': x, 'value': x})\n",
        "\n",
        "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
        "\n",
        "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
        "\n",
        "# 背景色と文字色の設定\n",
        "colors = {\n",
        "    'background': '#111111',\n",
        "    'text': '#7FDBFF'\n",
        "}\n",
        "\n",
        "app.layout = html.Div(style={'backgroundColor': colors['background']}, children=[\n",
        "    html.H1(\n",
        "      children='COVID19ダッシュボード',\n",
        "      style={'textAlign': 'center',\n",
        "            'color': colors['text']\n",
        "      }\n",
        "    ),\n",
        "\n",
        "    html.Div(\n",
        "      children='COVID19ワールドワイド及び日本国内感染者数情報', \n",
        "      style={'textAlign': 'center',\n",
        "        'color': colors['text']\n",
        "      }\n",
        "    ),\n",
        "\n",
        "    dcc.Dropdown(\n",
        "      id='my_ticker_symbol',\n",
        "      options=dict0,\n",
        "      value='Worldwide',\n",
        "    ),\n",
        "\n",
        "    dcc.Graph(\n",
        "        id='example-graph',\n",
        "        figure={\n",
        "            'data':[\n",
        "              {'x': df0_x, 'y': df0_y}\n",
        "            ],\n",
        "            'layout': {\n",
        "                'plot_bgcolor': colors['background'],\n",
        "                'paper_bgcolor': colors['background'],\n",
        "                'font': {\n",
        "                    'color': colors['text']\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    )\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "  Output('example-graph', 'figure'),\n",
        "  [Input('my_ticker_symbol', 'value')])\n",
        "\n",
        "def update_graph(stock_ticker):\n",
        "  df0_y = df0.loc[stock_ticker, ].tolist()\n",
        "  fig = {\n",
        "    'data':[\n",
        "      {'x': df0_x, 'y': df0_y}\n",
        "    ],\n",
        "    'layout': {\n",
        "      'title': stock_ticker,\n",
        "      'plot_bgcolor': colors['background'],\n",
        "      'paper_bgcolor': colors['background'],\n",
        "      'font': {'color': colors['text']}\n",
        "    }\n",
        "  }\n",
        "  return fig\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run_server(debug=True)\n",
        "\"\"\"\n",
        "\n",
        "with open('app.py', mode='w', encoding='utf_8') as f:\n",
        "  f.write(dashfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Won7cu4lkvHG",
        "colab_type": "text"
      },
      "source": [
        "### ngrok tonneling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMXNNayP9Ke7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 8050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "  \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "!python app.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idmKjYB9uBvD",
        "colab_type": "text"
      },
      "source": [
        "# Run main()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpynilp4t56D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python\n",
        "#-*- coding:utf-8 -*-\n",
        "\n",
        "def main():\n",
        "  import dldata\n",
        "  import time\n",
        "\n",
        "  dldata.down_load()\n",
        "  time.sleep(10)\n",
        "  \n",
        "  import app\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSRO_pcEKKl3",
        "colab_type": "text"
      },
      "source": [
        "# Test Program"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByBnUvzgLL9i",
        "colab_type": "text"
      },
      "source": [
        "### test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5kz6IUA_erO",
        "colab_type": "code",
        "outputId": "fce4ad52-cc47-4a04-c2d8-4eb5d1fa5231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import dash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "print(dcc.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1u97R7HBflh",
        "colab_type": "text"
      },
      "source": [
        "#### pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6-6VjhdBSWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip freeze\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxFOwuNzBi7h",
        "colab_type": "text"
      },
      "source": [
        "#### test program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYuVOyj6KNZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DIRCSV = 'static/csv/'\n",
        "CSV_FILES = ('covid19_ww_confirmed_global.csv',\n",
        "            'covid19_ww_deaths_global.csv',\n",
        "            'covid19_ww_recovered_global.csv',\n",
        "            'covid19_jp_all.csv')\n",
        "\n",
        "df0 = pd.read_csv(DIRCSV + CSV_FILES[0])\n",
        "df1 = pd.read_csv(DIRCSV + CSV_FILES[1])\n",
        "df2 = pd.read_csv(DIRCSV + CSV_FILES[2])\n",
        "df3 = pd.read_csv(DIRCSV + CSV_FILES[3])\n",
        "\n",
        "df0_date = df0.columns.values.tolist()\n",
        "df0_date = df0_date[1:]\n",
        "df0_countries = df0.iloc[:, 0].values.tolist()\n",
        "df0 = df0.set_index('Country/Region')\n",
        "\n",
        "df1_date = df1.columns.values.tolist()\n",
        "df1_date = df1_date[1:]\n",
        "df1_countries = df1.iloc[:, 0].values.tolist()\n",
        "df1 = df1.set_index('Country/Region')\n",
        "\n",
        "df2_date = df2.columns.values.tolist()\n",
        "df2_date = df2_date[1:]\n",
        "df2_countries = df2.iloc[:, 0].values.tolist()\n",
        "df2 = df2.set_index('Country/Region')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6yj-giPBWMt",
        "colab_type": "text"
      },
      "source": [
        "#### グラフ作成をマインプログラムから移動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No_6e1ko_wCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  ##グラフ作成をマインプログラムから移動\n",
        "  \n",
        "  \"\"\"\n",
        "  ## Total amount of confirmed, recovered, death in Japan\n",
        "  dfs = df.groupby('Status')\n",
        "  number = dfs['Number'].sum()\n",
        "  confirmed_total = number.loc[\"confirmed\"]\n",
        "  recovered_total = number.loc[\"recovered\"]\n",
        "  death_total = number.loc[\"death\"]\n",
        "  confirmed_total = confirmed_total + recovered_total + death_total\n",
        "  #print(confirmed_total, death_total, recovered_total)\n",
        "\n",
        "  ## Plot deily number of recovered, death in Japan\n",
        "  dfds = df.groupby(['Date', 'Status']).count()['Number'].unstack()\n",
        "  dfds = dfds.replace(np.nan, 0)\n",
        "  dfds = dfds.sort_index()\n",
        "  dfdsd = dfds.drop(\"confirmed\", axis=1)\n",
        "\n",
        "  labels = dfdsd.index.to_list()\n",
        "  height1 = dfdsd['recovered']\n",
        "  height2 = dfdsd['death']\n",
        "  left = np.arange(len(height1)) \n",
        "  width = 0.3\n",
        "  title=\"日毎退院者数（青）死亡者数（赤）\"\n",
        "  figure(num=None, figsize=(15, 6))\n",
        "  plt.bar(left, height1, color='b', width=width, align='center')\n",
        "  plt.bar(left+width, height2, color='r', width=width, align='center')\n",
        "  plt.xticks(left+width/2, labels)\n",
        "  plt.xticks(left[::7], labels[::7], rotation=90, size='small')\n",
        "  plt.title(title)\n",
        "  plt.savefig('static/img/COVID19_jp_daily_death.jpg')\n",
        "  plt.show()\n",
        "\n",
        "  ## Reshape daily amount of confirmed, recovered, death in Japan\n",
        "  amount_confirmed = 0\n",
        "  amount_recovered = 0\n",
        "  amount_death = 0\n",
        "  am_con = []\n",
        "  am_rec = []\n",
        "  am_det = []\n",
        "  for index, row in dfds.iterrows():\n",
        "    number_of_day_confirmed = row[0] #dfds.at[index, 'confirmed']\n",
        "    number_of_day_recovered = row[2] #dfds.at[index, 'recovered']\n",
        "    number_of_day_death = row[1] #dfds.at[index, 'death']\n",
        "    amount_confirmed = amount_confirmed + number_of_day_confirmed\n",
        "    amount_recovered = amount_recovered + number_of_day_recovered\n",
        "    amount_death = amount_death + number_of_day_death\n",
        "    am_con.append(amount_confirmed)\n",
        "    am_rec.append(amount_recovered)\n",
        "    am_det.append(amount_death)\n",
        "  dfds[\"Amount_confirmed\"] = am_con\n",
        "  dfds[\"Amount_recovered\"] = am_rec\n",
        "  dfds[\"Amount_death\"] = am_det\n",
        "  dfdsd = dfds.drop([\"confirmed\", \"recovered\", \"death\"], axis=1)\n",
        "\n",
        "  ## Plot daily amount of confirmed, recovered, death in Japan\n",
        "  fig, ax = plt.subplots(figsize=(15,7))\n",
        "  dfdsd.plot(ax=ax)\n",
        "  title=\"全国陽性者増加数\"\n",
        "  plt.title(title)\n",
        "  plt.savefig('static/img/COVID19_jp_total_confirmed.jpg')\n",
        "  plt.show()\n",
        "  dfdsdd = dfdsd.drop([\"Amount_confirmed\", \"Amount_recovered\"], axis=1)\n",
        "  fig, ax = plt.subplots(figsize=(15,7))\n",
        "  dfdsdd.plot(ax=ax)\n",
        "  title=\"全国死者増加数\"\n",
        "  plt.title(title)\n",
        "  plt.savefig('static/img/COVID19_jp_total_death.jpg')\n",
        "  plt.show()\n",
        "  dfdsdr = dfdsd.drop([\"Amount_confirmed\", \"Amount_death\"], axis=1)\n",
        "  fig, ax = plt.subplots(figsize=(15,7))\n",
        "  dfdsdr.plot(ax=ax)\n",
        "  title=\"全国退院者増加数\"\n",
        "  plt.title(title)\n",
        "  plt.savefig('static/img/COVID19_jp_total_recovered.jpg')\n",
        "  plt.show()\n",
        "\n",
        "  ## Amount of each prefecture\n",
        "  dfp = df.groupby('Prefecture')\n",
        "  number_list = dfp['Number'].sum()\n",
        "  dfp = number_list.sort_values(ascending=False)\n",
        "\n",
        "  ## Plot amount of each prefecture\n",
        "  title = \"都道府県別感染者総数\"\n",
        "  start = 0\n",
        "  limit = 47\n",
        "  list = dfp.index\n",
        "  list = list.values.tolist()\n",
        "  left_base = [num for num in range(len(list))]\n",
        "  height_base = dfp.values.tolist()\n",
        "  left = left_base[start:limit]\n",
        "  height = height_base[start:limit]\n",
        "  label = list[start:limit]\n",
        "  figure(num=None, figsize=(15, 6))\n",
        "  plt.bar(left, height, tick_label = label)\n",
        "  plt.xticks(left[::1], label[::1], rotation=80, size='large')\n",
        "  plt.title(title)\n",
        "  plt.savefig('static/img/COVID19_jpref_total_confirmed0020.jpg')\n",
        "  plt.show()\n",
        "  start = 20\n",
        "  limit = 40\n",
        "  left = left_base[start:limit]\n",
        "  height = height_base[start:limit]\n",
        "  label = list[start:limit]\n",
        "  figure(num=None, figsize=(15, 6))\n",
        "  plt.bar(left, height, tick_label = label)\n",
        "  plt.xticks(left[::1], label[::1], rotation=80, size='large')\n",
        "  plt.title(title)\n",
        "  plt.savefig('static/img/COVID19_jpref_total_confirmed2040.jpg')\n",
        "  plt.show()\n",
        "  start = 40\n",
        "  limit = 49\n",
        "  left = left_base[start:limit]\n",
        "  height = height_base[start:limit]\n",
        "  label = list[start:limit]\n",
        "  figure(num=None, figsize=(15, 6))\n",
        "  plt.bar(left, height, tick_label = label)\n",
        "  plt.xticks(left[::1], label[::1], rotation=80, size='large')\n",
        "  plt.title(title)\n",
        "  plt.savefig('static/img/COVID19_jpref_total_confirmed4047.jpg')\n",
        "  plt.show()\n",
        "\n",
        "  dfpd = df.groupby(['Date', 'Prefecture'])\n",
        "  number = dfpd['Number'].sum()\n",
        "  number = number.unstack()\n",
        "  number = number[list]\n",
        "  number = number.replace(np.nan, 0)\n",
        "  ###\n",
        "  col_range = list[:]\n",
        "  graph_number = number[col_range]\n",
        "  title = \"都道府県別日毎COVID19陽性発生件数\"\n",
        "  fig, ax = plt.subplots(figsize=(15,7))\n",
        "  graph_number.plot(ax=ax, title=title)\n",
        "  plt.savefig('static/img/COVID19_jpref_dailyall.jpg')\n",
        "  plt.show()\n",
        "  ###\n",
        "  col_range = list[0:5]\n",
        "  graph_number = number[col_range]\n",
        "  title = \"都道府県別日毎COVID19陽性発生件数\"\n",
        "  fig, ax = plt.subplots(figsize=(15,7))\n",
        "  graph_number.plot(ax=ax, title=title)\n",
        "  plt.savefig('static/img/COVID19_jpref_daily0005.jpg')\n",
        "  plt.show()\n",
        "  col_range = list[5:10]\n",
        "  graph_number = number[col_range]\n",
        "  title = \"都道府県別日毎COVID19陽性発生件数\"\n",
        "  fig, ax = plt.subplots(figsize=(15,7))\n",
        "  graph_number.plot(ax=ax, title=title)\n",
        "  plt.savefig('static/img/COVID19_jpref_daily0510.jpg')\n",
        "  plt.show()\n",
        "\n",
        "  dfn = df.groupby('Date')\n",
        "  number = dfn['Number'].sum()\n",
        "  title = \"全国日毎COVID19陽性発生件数\"\n",
        "  fig, ax = plt.subplots(figsize=(15,7))\n",
        "  number.plot(ax=ax, title=title)\n",
        "  plt.savefig('static/img/COVID19_jp_daily_confirmed.jpg')\n",
        "  plt.show()\n",
        "  \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWNHkitbBtBK",
        "colab_type": "text"
      },
      "source": [
        "#### test program2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY97TxeR2TF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import datetime\n",
        "import dash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DIRCSV = 'static/csv/'\n",
        "CSV_FILES = ('covid19_ww_confirmed_global.csv',\n",
        "            'covid19_ww_deaths_global.csv',\n",
        "            'covid19_ww_recovered_global.csv',\n",
        "            'covid19_jp_prf_cfm.csv',\n",
        "            'covid19_jp_prf_dth.csv',\n",
        "            'covid19_jp_prf_rcv.csv',\n",
        "            'covid19_jp_prf_male.csv',\n",
        "            'covid19_jp_prf_female.csv',\n",
        "            'covid19_jp_prf_gen.csv')\n",
        "\n",
        "df0 = pd.read_csv(DIRCSV + CSV_FILES[0])\n",
        "df1 = pd.read_csv(DIRCSV + CSV_FILES[1])\n",
        "df2 = pd.read_csv(DIRCSV + CSV_FILES[2])\n",
        "df3 = pd.read_csv(DIRCSV + CSV_FILES[3])\n",
        "df4 = pd.read_csv(DIRCSV + CSV_FILES[4])\n",
        "df5 = pd.read_csv(DIRCSV + CSV_FILES[5])\n",
        "df6 = pd.read_csv(DIRCSV + CSV_FILES[6])\n",
        "df7 = pd.read_csv(DIRCSV + CSV_FILES[7])\n",
        "df8 = pd.read_csv(DIRCSV + CSV_FILES[8])\n",
        "\n",
        "df0 = df0.set_index('Country/Region')\n",
        "df0.loc['Worldwide'] = df0.sum()\n",
        "df0_x = df0.columns.tolist()\n",
        "df0_y = df0.loc['Worldwide', ].tolist()\n",
        "df0_z = df00.index.tolist()\n",
        "dict0 = []\n",
        "for x in df0_z:\n",
        "  dict0.append({'lavel': x, 'value': x})\n",
        "print(df0)\n",
        "print(df0_x)\n",
        "print(df0_y)\n",
        "print(dict0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BICor1r1_dWv",
        "colab_type": "text"
      },
      "source": [
        "#### dash program core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WTWClqk_iOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import datetime\n",
        "import dash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "DIRCSV = 'static/csv/'\n",
        "CSV_FILES = ('covid19_ww_confirmed_global.csv',\n",
        "            'covid19_ww_deaths_global.csv',\n",
        "            'covid19_ww_recovered_global.csv',\n",
        "            'covid19_jp_prf_cfm.csv',\n",
        "            'covid19_jp_prf_dth.csv',\n",
        "            'covid19_jp_prf_rcv.csv',\n",
        "            'covid19_jp_prf_male.csv',\n",
        "            'covid19_jp_prf_female.csv',\n",
        "            'covid19_jp_prf_gen.csv')\n",
        "\n",
        "df0 = pd.read_csv(DIRCSV + CSV_FILES[0])\n",
        "df1 = pd.read_csv(DIRCSV + CSV_FILES[1])\n",
        "df2 = pd.read_csv(DIRCSV + CSV_FILES[2])\n",
        "df3 = pd.read_csv(DIRCSV + CSV_FILES[3])\n",
        "df4 = pd.read_csv(DIRCSV + CSV_FILES[4])\n",
        "df5 = pd.read_csv(DIRCSV + CSV_FILES[5])\n",
        "df6 = pd.read_csv(DIRCSV + CSV_FILES[6])\n",
        "df7 = pd.read_csv(DIRCSV + CSV_FILES[7])\n",
        "df8 = pd.read_csv(DIRCSV + CSV_FILES[8])\n",
        "\n",
        "df0 = df0.set_index('Country/Region')\n",
        "df0.loc['Worldwide'] = df0.sum()\n",
        "df0_x = df0.columns.tolist()\n",
        "df0_y = df0.loc['Worldwide', ].tolist()\n",
        "df0_z = df0.index.tolist()\n",
        "dict0 = []\n",
        "for x in df0_z:\n",
        "  dict0.append({'label': x, 'value': x})\n",
        "\n",
        "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
        "\n",
        "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
        "\n",
        "# 背景色と文字色の設定\n",
        "colors = {\n",
        "    'background': '#111111',\n",
        "    'text': '#7FDBFF'\n",
        "}\n",
        "\n",
        "app.layout = html.Div(style={'backgroundColor': colors['background']}, children=[\n",
        "    html.H1(\n",
        "      children='COVID19ダッシュボード',\n",
        "      style={'textAlign': 'center',\n",
        "            'color': colors['text']\n",
        "      }\n",
        "    ),\n",
        "\n",
        "    html.Div(\n",
        "      children='COVID19ワールドワイド及び日本国内感染者数情報', \n",
        "      style={'textAlign': 'center',\n",
        "        'color': colors['text']\n",
        "      }\n",
        "    ),\n",
        "\n",
        "    dcc.Dropdown(\n",
        "      id='my_ticker_symbol',\n",
        "      options=dict0,\n",
        "      value='Worldwide',\n",
        "    ),\n",
        "\n",
        "    dcc.Graph(\n",
        "        id='example-graph',\n",
        "        figure={\n",
        "            'data':[\n",
        "              {'x': df0_x, 'y': df0_y}\n",
        "            ],\n",
        "            'layout': {\n",
        "                'plot_bgcolor': colors['background'],\n",
        "                'paper_bgcolor': colors['background'],\n",
        "                'font': {\n",
        "                    'color': colors['text']\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    )\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "  Output('example-graph', 'figure'),\n",
        "  [Input('my_ticker_symbol', 'value')])\n",
        "\n",
        "def update_graph(stock_ticker):\n",
        "  df0_y = df0.loc[stock_ticker, ].tolist()\n",
        "  fig = {\n",
        "    'data':[\n",
        "      {'x': df0_x, 'y': df0_y}\n",
        "    ],\n",
        "    'layout': {\n",
        "      'title': stock_ticker,\n",
        "      'plot_bgcolor': colors['background'],\n",
        "      'paper_bgcolor': colors['background'],\n",
        "      'font': {'color': colors['text']}\n",
        "    }\n",
        "  }\n",
        "  return fig\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run_server(debug=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLLTJ84mI8P4",
        "colab_type": "text"
      },
      "source": [
        "#### sample app.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62qyZWe6I__a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "btsrp = \"\"\"\n",
        "import dash\n",
        "import dash_bootstrap_components as dbc\n",
        "\n",
        "app = dash.Dash()\n",
        "\n",
        "app.layout = dbc.Container(\n",
        "    dbc.Alert(\"Hello Bootstrap!\", color=\"success\"),\n",
        "    className=\"p-5\",\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server()\n",
        "\"\"\"\n",
        "\n",
        "with open('app.py', mode='w', encoding='utf_8') as f:\n",
        "  f.write(btsrp)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}